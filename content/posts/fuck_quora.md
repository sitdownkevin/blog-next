---
title: 和 Quora 战斗到底
tags: TECH
create_date: 2025-07-03
update_date: 2025-07-03
hidden: false
---

## 前言

最近，我接手了一个从 Quora 爬取数据的项目。目标是抓取大约 18000 个用户的主页，收集他们的详细信息，包括基本简介、粉丝和回答数等统计数据、个人履历等等。

![image-20250703004225432](https://raw.githubusercontent.com/sitdownkevin/ImageHosting/main/public/9f7f48d7d02d61b6c5d68b86f0632d2d.png)

我希望为每个用户生成结构清晰的 JSON 文件，格式如下：

```json
{
  "user_name": "",
  "user_url": "",
  "basic_info": {
    "name": "",
    "bio": ""
  },
  "stats": {
    "followers": "",
    "following": "",
    "answers": "",
    "questions": "",
    "posts": ""
  },
  "credentials": [],
  "spaces": [],
  "knows_about": [],
  "scraped_at": ""
}
```

Quora 的一个友好之处在于，无需登录即可查看用户主页。这意味着，理论上只要我能搞定基于 IP 的反爬虫策略，就能高效地完成任务。经过一番调研（感谢 Perplexity 的帮助），我发现 Webshare 提供的代理服务物美价廉——100个代理只需2.99美元，总带宽250GB，对于这次任务来说绰绰有余。

在技术栈方面，我选择了使用 Playwright 来模拟真实的用户操作。这虽然是我第一次使用它，但我还发现了一个名为 `patchright` 的“魔改”版，它在 Playwright 的基础上内置了许多反检测的增强功能，正合我意。

我为整个爬虫系统设计了如下的简单架构：

![image-20250703003900521](https://raw.githubusercontent.com/sitdownkevin/ImageHosting/main/public/95014db1c79f2c0b8052ceadc458f445.png)

架构说明：

- `Crawler`: 主进程，负责调度和编排所有模块。
- `Proxy`: 代理模块，从购买的代理池中随机返回一个可用代理。
- `Users`: 用户队列，用于管理待爬取用户的进度。
- `Patchright`: 核心执行者，负责浏览器自动化和数据抓取。
- `Parser` & `StoreToDb`: 负责解析原始数据、清洗并存入数据库。
- `Check`: 一个独立的检查模块，用于验证数据库中数据的正确性。

在爬取过程中，每个用户的数据都会被完整地保存下来，包括 `crawler.log`（日志）、`user_profile.html`（页面源码）、`user_profile.json`（解析后的数据）以及 `user_profile.png`（页面截图），统一存放在 `data/user/{user_name}` 目录下，为调试和验证提供了极大的便利。

为了节省流量和提升速度，我用了一个小技巧来阻止图片加载：

```python
await page.route(
    "**/*",
    lambda route: route.abort()
    if route.request.resource_type == "image"
    else route.continue_()
)
```

## 真正的挑战：如何最大化效率？

我花了一个下午搭建好了基本框架。框架能跑，但我很快就遇到了一个看似简单实则非常棘手的问题：**如何在不被封禁的前提下，将爬取效率最大化？**

我所有的爬取任务都是异步的。最初的策略非常简单粗暴：同时启动 N 个并发任务。但这很快就暴露了问题——由于网络延迟的存在，请求很容易在某些时刻“扎堆”发出，导致系统时而流量激增，时而又陷入空闲。

第一次优化，我引入了固定的任务启动间隔，比如每隔2秒启动一个新任务。情况有所好转，但新的问题又来了：

1. 这种固定间隔的请求模式太过“机器人化”，很容易被反爬系统检测到。
2. 效率太低。按这个速度，爬取一百万用户需要整整23天。
3. 我并没有充分利用服务器的承载能力和网络带宽。

### 突破口：像人一样思考

真正的突破源于一个简单的洞察：**人类的行为模式是随机的，但这种随机性遵循某种概率分布**。当我们浏览网页时，点击的间隔既不是固定的，也不是完全均匀随机的，而是遵循着某种特定的节奏。

经过一番研究，我发现**指数分布（Exponential Distribution）** 是模拟这种行为的绝佳模型。它能够完美地体现：

- 大部分操作间隔都很短（例如快速浏览）。
- 偶尔会出现较长的停顿（例如仔细阅读某段内容）。
- 整体呈现出一种自然的、无规律的随机性。

## 我的设计哲学

基于这一洞察，我设计了一套多层次的控制系统，目标是让我的爬虫表现得更像一群真实的用户。

### 并发控制：模拟多用户同时在线

```python
'max_concurrent': 30,  # 最大并发数
```

我选择了 30 作为最大并发数，这是一个权衡后的结果，主要基于我本地的带宽和购买的 Proxies 数量决定。

### 多层次延时系统

我设计了三个层次的延时机制，每一层都采用指数分布来生成随机延时，从而打造出无法预测的“人类”行为模式。

#### 1. 任务启动延时

这模拟了用户打开一个新页面的行为。

```python
'task_start_lambda': 2.0,  # 平均每 0.5 秒启动一个新任务
```

这里的 $\lambda$ 参数为 2.0，意味着任务启动的平均间隔是 $\frac{1}{\lambda}$ 为 0.5 秒。但每次的实际间隔都是从该分布中随机抽取的，从而形成了一个自然的、非均匀的启动序列。

#### 2. 请求延时

这是最核心的延时，它模仿了用户在页面上停留、阅读的时间。

```python
'request_delay_lambda': 0.3,
'request_delay_min': 0.5,
'request_delay_max': 30,
```

我设置了一个较小的 $\lambda$ 值 0.3，对应的平均延时约为 3.3 秒。同时，我将延时限制在 0.5 到 30 秒之间。这个设计精妙地模拟了多种场景：

- **快速点击**：0.5 秒
- **正常浏览**：3-5 秒
- **仔细阅读**：10-30 秒

#### 3. 批次延时

这模拟了人类的“疲劳效应”，没有人会连续几小时不停地浏览网页。

```python
'batch_delay_lambda': 0.1,
'batch_delay_min': 2.0,
'batch_delay_max': 10.0,
```

我设定每处理 200 个用户（一个批次）后，就让爬虫“休息”一下。这个延时同样服从指数分布，为爬取活动引入了更长时间的、更自然的停顿。

### 智能的批处理与重试策略

为了更好地管理内存和设置断点，我引入了批处理策略。

```python
'batch_size': 200,
```

按批处理有三大好处：

1. **内存管理**：避免一次性加载过多数据导致内存溢出。
2. **断点续爬**：每完成一批任务即可保存进度，即使意外中断也能从断点恢复。
3. **行为模拟**：人们在处理大型任务时，通常也会分阶段完成。

最后，我为网络请求失败设计了智能重试机制。

```python
'retry_attempts': 3,
'retry_delay_lambda': 0.2,
'retry_delay_min': 3.0,
'retry_delay_max': 15.0,
```

我没有采用“固定等待5秒后重试”这种机械的方式，而是让重试的等待时间也服从指数分布。这种“指数退避”策略，避免了传统重试逻辑的固定模式。

### 为什么选择指数分布？

你可能会问，为什么不用均匀分布（在某个范围内完全随机）或正态分布？因为指数分布有几个独特的优点：

1. **无记忆性**: 下一次事件发生需要等待的时间，与已经等待了多久无关。这非常符合人类行为的突发性和随机性。
2. **长尾特性**: 它天然地会产生少量、但数值很大的随机数，完美地模拟了真实用户偶尔出现的长时间停顿。
3. **参数简单**: 只需要一个 `lambda` 参数，就能控制整个分布的形态，非常易于调整。

## 实践是检验真理的唯一标准：模拟与验证

为了验证我这套设计哲学的合理性，在正式部署之前，我专门构建了一个离散事件模拟（Discrete Event Simulation）程序来测试系统的行为。结果令人振奋，完全证实了我的想法是正确且高效的。

![image-20250703004801426](https://raw.githubusercontent.com/sitdownkevin/ImageHosting/main/public/11083bba2191c5f66a939f343662e6c4.png)

从模拟结果的可视化图表和统计数据中，我们可以清晰地看到：

- **并发请求数**：并发数在我的上限 30 以下自然地波动，显示出极佳的资源利用率（并发利用率 60.6%），同时又避免了恒定不变的机器特征。
- **请求开始分布**：新任务的启动平稳但毫无规律，成功避免了固定的请求模式。
- **累计完成进度**：累计完成的请求数呈现出一条近乎完美的直线，表明系统拥有一个非常稳定和可预测的整体吞吐量（1.78 用户/秒）。
- **延时分布比较**：直方图清晰地展示了我所设计的延时符合指数分布：绝大多数延时都很短，同时拖着一条由少量长延时组成的“长尾”。

## 总结

这个项目是一次非常有趣的探索，带领我从一个简单的暴力爬虫，走向了一个精密的、由行为驱动的自动化系统。对我而言，最大的收获是：**在进行大规模数据爬取时，单纯追求速度和并发是远远不够的，真正的艺术在于“融入环境”**。

通过使用指数分布等工具来模拟人类行为中那些微妙的、随机的模式，我成功构建了一个不仅高效，而且稳定、对目标平台更友好的爬虫。这是一个有力的提醒——有时候，最有效的解决方案，是那个最能模仿自然的方案。
